# -*- coding: utf-8 -*-
"""News_Cleaning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1z4PKnYft5ODNT_86a1zH4KjIkdV1I0d7
"""

import re
import unicodedata

import pandas as pd
import torch
from google.colab import userdata

BASE_PATH = userdata.get("BASE_PATH")


class TitlesCleaner:
    def __init__(self):
        self.allowed_symbols = r"\$\€\£\¥\₿\%\+\-\/\*×÷\(\)\[\]\.:,;[-]"
        self.clean_re = re.compile(
            rf"[^0-9A-Za-zÁÉÍÓÚáéíóúÑñÜü{self.allowed_symbols} ]+"
        )
        self.multispace_re = re.compile(r"\s+")

    def _normalize(self, text):
        """
        1. All titles to lowercase
        2. Remove extra spaces or break lines
        3. Remove no financial symbols
        """

        s = str(text).lower()

        # html
        s = re.sub(r"<.*?>", " ", s)
        # urls
        s = re.sub(r"http\S+|www\.\S+", " ", s)
        # email
        s = re.sub(r"\S+@\S+", " ", s)

        # deletes accents
        # maybe not necessary after translation to english
        # s = ''.join(
        #  c for c in unicodedata.normalize('NFD', s)
        #  if unicodedata.category(c) != 'Mn'
        # )

        # substitutes any symbol that is not in self.clean_re for ""
        s = self.clean_re.sub("", s)

        # 3 . 86 -> 3.86
        s = re.sub(r"(\d)\s*([.,])\s*(\d)", r"\1\2\3", s)

        # 3.86 % -> 3.86%
        # or the other side
        s = re.sub(r"(\d)\s*([%$€£¥₿])", r"\1\2", s)

        # Deletes any residual space
        s = re.sub(r"\s+", " ", s).strip()

        return s

    def start_clean(self, df):
        df = df.copy()
        col = "title"

        df[col] = df[col].apply(self._normalize)
        print("Done normalized")

        # print("Translating titles...")
        # df['title_english'] = [self._translate(t, l) for t, l in zip(df[col], df['language'])]

        return df


country = "mexico"
path = f"{BASE_PATH}/base_clean_{country}.csv"

df = pd.read_csv(f"{path}")

cleaner = TitlesCleaner()

df = cleaner.start_clean(df)
