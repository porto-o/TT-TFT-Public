# -*- coding: utf-8 -*-
"""EDA_News_tt.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JJTsX22K6hoypks8_j41e1cxmbWVHCxG
"""

# @title
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_extraction.text import CountVectorizer

from google.colab import userdata

BASE_PATH = userdata.get('BASE_PATH')

# @title
def boxplot(df_copy):
    sns.set_theme(style="whitegrid")
    fig, axes = plt.subplots(1, 2, figsize=(12, 4))

    # char
    sns.boxplot(x=df_copy['title_length'], color='skyblue', ax=axes[0])
    axes[0].set_title('Distribución de longitud de títulos', fontsize=12, fontweight='bold')
    axes[0].set_xlabel('Longitud (caracteres)')
    axes[0].set_ylabel('')

    # words
    sns.boxplot(x=df_copy['word_count'], color='lightgreen', ax=axes[1])
    axes[1].set_title('Distribución de número de palabras', fontsize=12, fontweight='bold')
    axes[1].set_xlabel('Número de palabras')
    axes[1].set_ylabel('')

    plt.tight_layout()
    plt.show()

# @title
import matplotlib.pyplot as plt
import numpy as np

def plot_pareto(df_counts: pd.DataFrame, col_name: str = 'domain'):
    df_sorted = df_counts.sort_values('count', ascending=False)

    counts = df_sorted['count']
    categories = df_sorted.index.astype(str)

    # Cálculo acumulado en porcentaje
    cumulative_percentage = counts.cumsum() / counts.sum() * 100

    # Ubicación donde se alcanza el 80%
    cutoff_idx = np.argmax(cumulative_percentage >= 80)

    fig, ax1 = plt.subplots(figsize=(10,6))

    ax1.bar(categories, counts, color='skyblue')
    ax1.set_ylabel('Conteo', color='blue')
    ax1.tick_params(axis='y', labelcolor='blue')
    ax1.set_xticklabels(categories, rotation=45, ha='right')

    # Línea de acumulado porcentual
    ax2 = ax1.twinx()
    ax2.plot(categories, cumulative_percentage, color='red', marker='o', linestyle='-', linewidth=2)
    ax2.set_ylabel('Acumulado %', color='red')
    ax2.tick_params(axis='y', labelcolor='red')
    ax2.axhline(80, color='green', linestyle='--', linewidth=1)

    # Marca vertical del corte 80%
    ax2.axvline(cutoff_idx, color='purple', linestyle='--', linewidth=1)

    plt.title(f'Pareto de {col_name}' if col_name else 'Gráfico de Pareto')
    plt.tight_layout()
    plt.show()

"""# Análisis exploratorio de noticias

- [X] Conteo de duplicados por `conjunto`
- [X] Métricas de longitudes de los titulares (por caractéres y palabras)
- [X] Palabras más repetidas, 1-grama y n-gramas *
- [X] Proporción de dominios
- [ ] Nulos por fecha en títulos
"""

def compound_duplicates(df: pd.DataFrame, subset=['title', 'seendate', 'domain']):
  """
    Show the total duplicates on df based on subset,}
    along with the proportion.
  """
  total_dup = df.duplicated(subset=subset).sum()
  perc = (total_dup * 100) / df.shape[0]

  print("\n" + "=" * 90)
  print("DUPLICADOS EN CONJUNTO".center(90))
  print("=" * 90)
  print(f"\nColumnas evaluadas: {subset}")
  print(f"Total de duplicados: {total_dup:,}")
  print(f"Proporción: {perc:.2f}% del total ({df.shape[0]:,} filas)\n")
  print("*" * 90 + "\n")

def stats_titles(df: pd.DataFrame, text_col='title', show_charts: bool = False):
    df_copy = df.copy()
    titles = df_copy[text_col].dropna().astype(str)

    df_copy['title_length'] = titles.apply(len)
    df_copy['word_count'] = titles.apply(lambda x: len(x.split()))

    print("\n" + "="*90)
    print("ANÁLISIS DE TITULARES".center(90))
    print("="*90)

    print("-"*90)
    print("MÉTRICAS POR CARACTERES")
    print("-"*90)
    print(df_copy['title_length'].describe().to_string())

    print("\n" + "-"*90)
    print("MÉTRICAS POR PALABRAS")
    print("-"*90)
    print(df_copy['word_count'].describe().to_string())

    if show_charts:
        print("\n" + "-"*90)
        print("GRÁFICAS")
        print("-"*90)
        boxplot(df_copy)

    print("\n" + "-"*90)
    print("EJEMPLOS")
    print("-"*90)
    shortest_title = df_copy.loc[df_copy['title_length'].idxmin(), text_col]
    longest_title = df_copy.loc[df_copy['title_length'].idxmax(), text_col]

    print("Título más corto:\n" + shortest_title)
    print("\nTítulo más largo:\n" + longest_title)
    print("*"*90 + "\n")

def cat_col_analysis(df: pd.DataFrame, col: str = 'domain'):
    df_copy = df.copy()

    counts = df_copy[col].value_counts(dropna=False)
    proportion = df_copy[col].value_counts(normalize=True, dropna=False) * 100

    result = pd.DataFrame({
        'count': counts,
        'percentage': proportion
    })

    print("\n" + "="*90)
    print(f"ANÁLISIS DE COLUMNA: {col.upper()}".center(90))
    print("="*90)

    print("-"*90)
    print("CONTEO Y PORCENTAJE POR CATEGORÍA")
    print("-"*90)
    print(result.to_string())

    print("\n" + "-"*90)
    print("EJEMPLOS DE CATEGORÍAS")
    print("-"*90)
    print("Categoría más frecuente:", counts.idxmax())
    print("Categoría menos frecuente:", counts.idxmin())
    print("*"*90 + "\n")

    plot_pareto(result, col_name=col)

def top_ngrams(df, text_col='title', n=20, ngram_range=(2,5), min_df=1, show_examples=3):
    """
    Muestra las palabras o n-gramas más frecuentes en una columna de texto.

    Args:
        df: DataFrame con la columna de texto
        text_col: columna de texto a analizar
        n: cantidad de n-gramas a mostrar
        ngram_range: rango de n-gramas (min_n, max_n)
        min_df: mínimo número de documentos donde aparece el n-grama
        show_examples: cuántos ejemplos mostrar
    """
    texts = df[text_col].dropna().astype(str)
    vectorizer = CountVectorizer(ngram_range=ngram_range, min_df=min_df)
    X = vectorizer.fit_transform(texts)

    freqs = X.sum(axis=0).A1
    terms = vectorizer.get_feature_names_out()

    df_freq = pd.DataFrame({'ngram': terms, 'count': freqs}).sort_values('count', ascending=False)

    print("\n" + "="*90)
    print(f"TOP {n} {'PALABRAS' if ngram_range==(1,1) else f'{ngram_range[0]}-{ngram_range[1]} GRAMAS'} EN '{text_col.upper()}'".center(90))
    print("="*90)
    print(df_freq.head(n).to_string(index=False))

    print("\n" + "-"*90)
    print(f"EJEMPLOS DE N-GRAMAS MÁS FRECUENTES ({show_examples})")
    print("-"*90)
    for _, row in df_freq.head(show_examples).iterrows():
        print(f"{row['ngram']}: {row['count']} veces")
    print("*"*90 + "\n")

    return df_freq.head(n)

def nulls_over_time(df: pd.DataFrame):
  """
    1. Imprime el total de nulos por columna
    2. Imprime la lista de fechas donde el titular es nulo
    3. Muestra esa información en una serie de tiempo
    """
  print("\n" + "="*80)
  print("NULOS POR COLUMNA".center(80))
  print("="*80)
  print(df.isna().sum())


  null_titles = df[df['title'].isna()]
  null_titles['date_cdmx'] = pd.to_datetime(null_titles['date_cdmx'], errors='coerce')

  if null_titles.empty:
    print("\nNo hay títulos nulos.")
    return

  min_date = pd.to_datetime(df['date_cdmx']).min()
  max_date = pd.to_datetime(df['date_cdmx']).max() # maxima en el rango de nulos

  print("\n" + "-"*80)
  print(f"Fechas con títulos nulos desde {min_date.date()} hasta {max_date.date()}".center(80))
  print("-"*80)
  fechas = null_titles['date_cdmx'].astype(str).sort_values().to_list()
  print(f'Total de fechas con títulos nulos {len(fechas)}')
  for _ in fechas:
    print(_)

def get_missing_dates(df: pd.DataFrame, date_col: str = 'date_cdmx'):
    """
    Dado el rango mínimo y máximo de fechas en `date_col`,
    devuelve una lista de fechas faltantes en el DataFrame.
    """
    df[date_col] = pd.to_datetime(df[date_col])

    date_range = pd.date_range(df[date_col].min(), df[date_col].max())

    missing_dates = date_range.difference(df[date_col].dt.normalize())

    if missing_dates.empty:
        print("No faltan fechas en el rango.")
    else:
        print(f"Faltan {len(missing_dates)} fechas:")
        for d in missing_dates:
            print(d.date())

def start_analysis(country="mexico"):
  path = f'{BASE_PATH}/base_clean_{country}.csv'

  df = pd.read_csv(f'{path}')

  print("#"*10, f'{country.upper()}', "#"*10)

  # Duplicados en conjunto
  compound_duplicates(df)

  # Métricas de titulos
  stats_titles(df=df, show_charts=True)

  # Dominios
  cat_col_analysis(df)

  # Palabras freq
  #top_ngrams(df)

  # Languages
  #cat_col_analysis(df, 'language')

  # Nulos
  nulls_over_time(df)

  # Fechas faltantes
  get_missing_dates(df)

start_analysis('brasil')

